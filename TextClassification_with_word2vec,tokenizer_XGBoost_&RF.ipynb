{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassification with  word2vec,tokenizer XGBoost &RF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-KG9Sehmaox"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "FK74JsR8TBRJ",
        "outputId": "776da4e5-256b-4569-8486-f430eaa4086f"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/content/java-8\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.11\" 2021-04-20\n",
            "OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n",
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "py4j"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/35/3d06b93fefdeab0f6f544b1fc48e5e49c049697c38611ef870383031380b/spark_nlp-3.0.3-py2.py3-none-any.whl (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-3.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkCMfZj-RYFK"
      },
      "source": [
        "\n",
        "from pyspark.sql.types import StructType,StructField,DoubleType\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFdmLJz0-TrN"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark import SparkContext\n",
        "sc =SparkContext()\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEUKLAIeriFS",
        "outputId": "1e1d38a7-a53a-412d-9d5a-ec9869984e6d"
      },
      "source": [
        "Review_df =sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('Reviews.csv')\n",
        "Review_df.show(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "| Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "|  1|B001E4KFG0|A3SGXH7AUHU8GW|          delmartian|                   1|                     1|    5|1303862400|Good Quality Dog ...|I have bought sev...|\n",
            "|  2|B00813GRG4|A1D87F6ZCVE5NK|              dll pa|                   0|                     0|    1|1346976000|   Not as Advertised|\"Product arrived ...|\n",
            "|  3|B000LQOCH0| ABXLMWJIXXAIN|\"Natalia Corres \"...|                   1|                     1|    4|1219017600|\"\"\"Delight\"\" says...|\"This is a confec...|\n",
            "|  4|B000UA0QIQ|A395BORC6FGVXV|                Karl|                   3|                     3|    2|1307923200|      Cough Medicine|If you are lookin...|\n",
            "|  5|B006K2ZZ7K|A1UQRSCLF8GW1T|\"Michael D. Bigha...|                   0|                     0|    5|1350777600|         Great taffy|Great taffy at a ...|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqYHIlvYriIi",
        "outputId": "1e721a12-260d-44b4-cf43-1d44f45e38e0"
      },
      "source": [
        "Review_df.printSchema()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- ProductId: string (nullable = true)\n",
            " |-- UserId: string (nullable = true)\n",
            " |-- ProfileName: string (nullable = true)\n",
            " |-- HelpfulnessNumerator: string (nullable = true)\n",
            " |-- HelpfulnessDenominator: string (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            " |-- Time: string (nullable = true)\n",
            " |-- Summary: string (nullable = true)\n",
            " |-- Text: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vjGX8qqriL0"
      },
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCOE3axYriPP"
      },
      "source": [
        "def partition(x):\n",
        "   return 1 if str(x)>str(3) else 0\n",
        "my_udf = udf(partition, IntegerType())  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGjfdhworiSo",
        "outputId": "f98aba29-936a-4e2d-e3f5-59e5cc47434d"
      },
      "source": [
        "Review_df = Review_df.withColumn('Score', my_udf('Score'))\n",
        "Review_df.show(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "| Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "|  1|B001E4KFG0|A3SGXH7AUHU8GW|          delmartian|                   1|                     1|    1|1303862400|Good Quality Dog ...|I have bought sev...|\n",
            "|  2|B00813GRG4|A1D87F6ZCVE5NK|              dll pa|                   0|                     0|    0|1346976000|   Not as Advertised|\"Product arrived ...|\n",
            "|  3|B000LQOCH0| ABXLMWJIXXAIN|\"Natalia Corres \"...|                   1|                     1|    1|1219017600|\"\"\"Delight\"\" says...|\"This is a confec...|\n",
            "|  4|B000UA0QIQ|A395BORC6FGVXV|                Karl|                   3|                     3|    0|1307923200|      Cough Medicine|If you are lookin...|\n",
            "|  5|B006K2ZZ7K|A1UQRSCLF8GW1T|\"Michael D. Bigha...|                   0|                     0|    1|1350777600|         Great taffy|Great taffy at a ...|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75blAT_VriVy",
        "outputId": "1459d923-a035-4dbd-c2d4-a846c6381405"
      },
      "source": [
        "if Review_df.count() > Review_df.dropDuplicates(['UserId','ProfileName','Time','Text']).count():\n",
        "   print ('Data has duplicates')\n",
        "print (\"Row count Now:\",Review_df.count())\n",
        "Review_df = Review_df.dropDuplicates(['UserId','ProfileName','Time','Text'])\n",
        "print (\"After Removing the duplicates, row count becomes:\")\n",
        "Review_df.count()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has duplicates\n",
            "Row count Now: 568454\n",
            "After Removing the duplicates, row count becomes:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "393559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXNZilhjriZ6",
        "outputId": "6f772432-3cc8-4b80-e31c-f13604ef12bb"
      },
      "source": [
        "Review_df.groupBy('Score').count().show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|Score| count|\n",
            "+-----+------+\n",
            "|    1|305599|\n",
            "|    0| 87960|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKpiua0Dric-"
      },
      "source": [
        "import gensim.parsing.preprocessing as gsp\n",
        "from pyspark.sql.types import StringType\n",
        "from gensim import utils\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JSd6Edrrigb"
      },
      "source": [
        "filters = [\n",
        "           gsp.strip_tags, \n",
        "           gsp.strip_punctuation,\n",
        "           gsp.strip_multiple_whitespaces,\n",
        "           gsp.strip_numeric,\n",
        "           gsp.remove_stopwords, \n",
        "           gsp.strip_short, \n",
        "           gsp.stem_text\n",
        "          ]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLeeqkf1rikK"
      },
      "source": [
        "def clean_text(x):\n",
        "    s = x[9]\n",
        "    s = s.lower()\n",
        "    s = utils.to_unicode(s)\n",
        "    for f in filters:\n",
        "        s = f(s)\n",
        "    return (x[6],s)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcdAidTXrinn"
      },
      "source": [
        "input_rdd = Review_df.rdd.map(lambda x : clean_text(x))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGo-2PbsrirC",
        "outputId": "ec63973e-80b4-4cca-f11d-da1af13b4529"
      },
      "source": [
        "input_df = input_rdd.toDF(['Score','Text'])\n",
        "input_df.show(10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|Score|                Text|\n",
            "+-----+--------------------+\n",
            "|    1|water water right...|\n",
            "|    0|grow visit grandp...|\n",
            "|    0|thought get good ...|\n",
            "|    1|order product rea...|\n",
            "|    1|long time fan cry...|\n",
            "|    1|product past have...|\n",
            "|    1|delic candi love ...|\n",
            "|    1|faint heart best ...|\n",
            "|    1|real fan bamboo s...|\n",
            "|    1|gave differ flavo...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlGPI8m1riud"
      },
      "source": [
        "input_df = input_df.dropna()\n",
        "train_df, test_df = input_df.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQWM2-HqMPVE"
      },
      "source": [
        "from pyspark.ml.feature import Word2Vec\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D989zL2lRbqq"
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"Text\",outputCol=\"words\")\n",
        "w2v = Word2Vec(vectorSize=300, minCount=0, inputCol=\"words\", outputCol=\"features\")\n",
        "doc2vec_pipeline = Pipeline(stages=[tokenizer,w2v])\n",
        "doc2vec_model = doc2vec_pipeline.fit(train_df)\n",
        "train_df = doc2vec_model.transform(train_df)\n",
        "test_df = doc2vec_model.transform(test_df)\n",
        "print (\"few rows from train df\")\n",
        "train_df.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-HX1eAXRcqw"
      },
      "source": [
        "def RandomForestCV(train_df,test_df):\n",
        "    rf = RandomForestClassifier(labelCol=\"Score\", featuresCol=\"features\")\n",
        "    pipeline = Pipeline(stages=[rf])\n",
        "    paramGrid = ParamGridBuilder().addGrid(rf.maxDepth, [5, 10]).addGrid(rf.maxBins, [25, 31]) .addGrid(rf.minInfoGain, [0.01, 0.001])\n",
        "    .addGrid(rf.numTrees, [20, 60]) .addGrid(rf.impurity, [\"gini\", \"entropy\"]) .build()\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=\"Score\")\n",
        "    crossValidator = CrossValidator(estimator=pipeline,evaluator=evaluator,estimatorParamMaps=paramGrid,numFolds=10)\n",
        "    cv = crossValidator.fit(train_df)\n",
        "    best_model = cv.bestModel.stages[0]\n",
        "    prediction = best_model.transform(test_df)\n",
        "    metric = evaluator.evaluate(prediction)\n",
        "    print (\"The metric of test's accuracy= %g\" % metric)    \n",
        "RandomForestCV(train_df,test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AKKEkDYMPud"
      },
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_features = train_df.select(\"features\").collect()\n",
        "train_lables = train_df.select(\"Score\").collect()\n",
        "test_features = test_df.select(\"features\").collect()\n",
        "test_labels = test_df.select(\"Score\").collect()\n",
        "\n",
        "\n",
        "X_train = np.asarray([v[0].toArray() for v in train_features])\n",
        "Y_train = np.asarray([v[0] for v in train_lables])\n",
        "X_test =  np.asarray([v[0].toArray() for v in test_features])\n",
        "Y_test = np.asarray([v[0] for v in test_labels])\n",
        "\n",
        "xgbClassifier = xgb.XGBClassifier(max_depth=10, seed=18238, objective='multi:softmax',num_class = 2)\n",
        "model = xgbClassifier.fit(X_train, Y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "auc_score = accuracy_score(Y_test,pred)\n",
        "print (\"The accuracy score for XGboost model : \",auc_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Usjy9-MPxo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44M6lbmtMP1Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmv3fxbXMP5R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozLPHJRnMP8g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKxxWjIdMP_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGZltAXQMQDM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKQzQzZeMQGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBywrcCFMQKa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWTR-Z1bMQN9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}